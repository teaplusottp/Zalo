{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bb9ca9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3976\\992302284.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import json\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from PIL import Image\n",
    "\n",
    "# Thêm đường dẫn hiện tại để import được các class từ file predict.py\n",
    "sys.path.append('/code')\n",
    "\n",
    "# Import các class từ code của bạn (Giả sử file code của bạn tên là predict.py)\n",
    "# Lưu ý: Bạn cần đảm bảo file predict.py đã xóa đoạn login huggingface và sửa đường dẫn load model\n",
    "from final4_optimized import Config, SimilarityModel, ObjectAwareModel, Sam, TinyViT, PromptEncoder, MaskDecoder, TwoWayTransformer, SamPredictor, associate_detections_to_trackers, KalmanBoxTracker\n",
    "\n",
    "# Hàm cố định seed (Bắt buộc)\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(42)\n",
    "print(\"✅ Environment setup & Seed fixed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3264b7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Cấu hình đường dẫn cho môi trường Docker\n",
    "class DockerConfig(Config):\n",
    "    def __init__(self, video_id):\n",
    "        super().__init__(video_id)\n",
    "        # GHI ĐÈ CÁC ĐƯỜNG DẪN CHO DOCKER\n",
    "        self.data_base = \"/data/samples\"  # Folder chứa data test được mount vào\n",
    "        self.segment_base = \"/segment_objects\" # Folder chứa template images\n",
    "        self.results_base = \"/result\"     # Folder output\n",
    "        \n",
    "        self.video_path = os.path.join(self.data_base, video_id, \"drone_video.mp4\")\n",
    "        self.template_img_dir = os.path.join(self.segment_base, video_id, \"original_images\")\n",
    "        self.template_mask_dir = os.path.join(self.segment_base, video_id, \"mask_images\")\n",
    "        \n",
    "        # Cấu hình Model (Load từ Local - QUAN TRỌNG: Phải tải weight về bỏ vào folder trong docker)\n",
    "        self.dino_model_id = \"./weight/DINO\" # Sửa lại path này trỏ tới feature extractor local\n",
    "        self.sam_checkpoint = './weight/mobile_sam.pt'\n",
    "        self.yolo_model = './weight/ObjectAwareModel.pt'\n",
    "        \n",
    "        # Tạo folder kết quả nếu chưa có\n",
    "        os.makedirs(self.results_base, exist_ok=True)\n",
    "\n",
    "# Khởi tạo một Config giả để load model trước (video_id tạm)\n",
    "dummy_cfg = DockerConfig(\"dummy\")\n",
    "\n",
    "print(\"⏳ Loading Models...\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# 1. Load Similarity Model (DINOv3)\n",
    "sim_model = SimilarityModel(dummy_cfg)\n",
    "\n",
    "# 2. Load YOLO\n",
    "yolo = ObjectAwareModel(dummy_cfg.yolo_model)\n",
    "\n",
    "# 3. Load SAM\n",
    "sam = Sam(image_encoder=TinyViT(img_size=1024, in_chans=3, num_classes=1000,\n",
    "                                embed_dims=[64,128,160,320], depths=[2,2,6,2],\n",
    "                                num_heads=[2,4,5,10], window_sizes=[7,7,14,7]),\n",
    "          prompt_encoder=PromptEncoder(embed_dim=256, image_embedding_size=(64,64),\n",
    "                                       input_image_size=(1024,1024), mask_in_chans=16),\n",
    "          mask_decoder=MaskDecoder(num_multimask_outputs=3,\n",
    "                                   transformer=TwoWayTransformer(depth=2, embedding_dim=256, mlp_dim=2048, num_heads=8),\n",
    "                                   transformer_dim=256))\n",
    "\n",
    "if os.path.exists(dummy_cfg.sam_checkpoint):\n",
    "    sam.load_state_dict(torch.load(dummy_cfg.sam_checkpoint, map_location=device), strict=False)\n",
    "else:\n",
    "    print(f\"❌ Warning: SAM checkpoint not found at {dummy_cfg.sam_checkpoint}\")\n",
    "\n",
    "sam.to(device).eval()\n",
    "predictor = SamPredictor(sam)\n",
    "\n",
    "print(\"✅ All Models Loaded Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688613a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy danh sách các folder video trong thư mục /data/samples\n",
    "# Cấu trúc giả định: /data/samples/VideoID/drone_video.mp4\n",
    "search_path = \"/data/samples/*\"\n",
    "test_cases = [os.path.basename(p) for p in glob.glob(search_path) if os.path.isdir(p)]\n",
    "\n",
    "print(f\"Found {len(test_cases)} test cases: {test_cases}\")\n",
    "\n",
    "all_predicted_time = []\n",
    "all_results_json = {} # Dictionary để lưu kết quả gộp\n",
    "\n",
    "for video_id in test_cases:\n",
    "    print(f\"▶️ Processing {video_id}...\")\n",
    "    \n",
    "    # --- BẮT ĐẦU ĐO THỜI GIAN ---\n",
    "    t1 = time()\n",
    "    \n",
    "    # 1. Setup Config riêng cho video này\n",
    "    cfg = DockerConfig(video_id)\n",
    "    \n",
    "    # 2. Load Templates (Tính vào thời gian xử lý vì mỗi video template khác nhau)\n",
    "    # Lưu ý: Nếu template load thất bại thì skip\n",
    "    try:\n",
    "        sim_model.load_templates(cfg.template_img_dir, cfg.template_mask_dir)\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {video_id} due to template error: {e}\")\n",
    "        # Vẫn ghi thời gian dù lỗi để không bị crash chấm điểm\n",
    "        t2 = time()\n",
    "        predicted_time = int((t2 - t1) * 1000)\n",
    "        all_predicted_time.append({\"id\": video_id, \"answer\": \"error\", \"time\": predicted_time})\n",
    "        continue\n",
    "\n",
    "    # 3. Video Setup\n",
    "    cap = cv2.VideoCapture(cfg.video_path)\n",
    "    W, H = int(cap.get(3)), int(cap.get(4))\n",
    "    \n",
    "    # Reset Trackers\n",
    "    trackers = []\n",
    "    KalmanBoxTracker.count = 0\n",
    "    final_predictions = []\n",
    "    frame_idx = 0 # Bắt đầu từ 0 hoặc đọc từ cfg.start_time nếu cần logic cắt video\n",
    "    \n",
    "    # Loop Frames\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "        \n",
    "        # --- LOGIC CHÍNH (Copy từ main loop của bạn) ---\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # YOLO Detect\n",
    "        results = yolo(rgb, conf=cfg.conf_thres, verbose=False)\n",
    "        boxes = results[0].boxes.xyxy.cpu().numpy() if results and results[0].boxes is not None else []\n",
    "        \n",
    "        high_score_candidates = []\n",
    "        if len(boxes) > 0:\n",
    "            predictor.set_image(rgb)\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "                # Check area ratio\n",
    "                if not (cfg.min_area_ratio <= (x2-x1)*(y2-y1)/(W*H) <= cfg.max_area_ratio): continue\n",
    "\n",
    "                masks, _, _ = predictor.predict(box=box, multimask_output=False)\n",
    "                if len(masks) == 0: continue\n",
    "                mask = masks[0]\n",
    "                \n",
    "                # Crop & Feature\n",
    "                yy, xx = np.where(mask)\n",
    "                if len(yy) == 0: continue\n",
    "                y1b, y2b, x1b, x2b = yy.min(), yy.max()+1, xx.min(), xx.max()+1\n",
    "                crop = rgb[y1b:y2b, x1b:x2b]\n",
    "                crop_mask = mask[y1b:y2b, x1b:x2b]\n",
    "                \n",
    "                feat = sim_model.extract_features(Image.fromarray(crop), crop_mask)\n",
    "                s1, s2, s3, avg_match, app_bonus = sim_model.compute_scores(feat)\n",
    "                size_pen = sim_model.size_penalty([x1b, y1b, x2b, y2b], W * H)\n",
    "                final_score = 0.7 * avg_match + 0.25 * app_bonus + 0.05 * size_pen\n",
    "                \n",
    "                if final_score > cfg.SCORE_THRESHOLD:\n",
    "                    high_score_candidates.append({\n",
    "                        'bbox': np.array([x1b, y1b, x2b, y2b]), \n",
    "                        'score': final_score\n",
    "                    })\n",
    "        \n",
    "        # SORT Tracking\n",
    "        if len(high_score_candidates) > 0:\n",
    "            dets_for_track = np.array([c['bbox'] for c in high_score_candidates])\n",
    "        else:\n",
    "            dets_for_track = np.empty((0, 4))\n",
    "            \n",
    "        trks_for_track = np.zeros((len(trackers), 4))\n",
    "        to_del = []\n",
    "        for t, trk in enumerate(trackers):\n",
    "            pos = trk.predict()[0]\n",
    "            trks_for_track[t, :] = [pos[0], pos[1], pos[2], pos[3]]\n",
    "            if np.any(np.isnan(pos)): to_del.append(t)\n",
    "        for t in reversed(to_del): trackers.pop(t)\n",
    "\n",
    "        matched, unmatched_dets, unmatched_trks = associate_detections_to_trackers(dets_for_track, trks_for_track, iou_threshold=cfg.IOU_THRESHOLD)\n",
    "\n",
    "        for m in matched:\n",
    "            trackers[m[1]].update(dets_for_track[m[0]], score=high_score_candidates[m[0]]['score'])\n",
    "        for i in unmatched_dets:\n",
    "            trk = KalmanBoxTracker(dets_for_track[i])\n",
    "            trk.update(dets_for_track[i], score=high_score_candidates[i]['score'])\n",
    "            trackers.append(trk)\n",
    "\n",
    "        # Get Best Tracker\n",
    "        active_trackers = []\n",
    "        for i, trk in enumerate(trackers):\n",
    "             # Logic visualize/save của bạn: hit_streak >= MIN_HITS or frame mới\n",
    "             if (trk.time_since_update < 1) and (trk.hit_streak >= cfg.MIN_HITS or frame_idx <= 5): \n",
    "                active_trackers.append({\"bbox\": trk.get_state()[0], \"score\": trk.last_score, \"id\": trk.id})\n",
    "        \n",
    "        best_obj = max(active_trackers, key=lambda x: x['score']) if active_trackers else None\n",
    "        \n",
    "        # Save Frame Result\n",
    "        frame_res = {\n",
    "            \"frame_id\": frame_idx,\n",
    "            \"box\": best_obj['bbox'].astype(int).tolist() if best_obj else [],\n",
    "            \"score\": float(best_obj['score']) if best_obj else 0.0,\n",
    "            \"track_id\": int(best_obj['id']) if best_obj else -1\n",
    "        }\n",
    "        final_predictions.append(frame_res)\n",
    "        frame_idx += 1\n",
    "        \n",
    "    cap.release()\n",
    "    # --- KẾT THÚC ĐO THỜI GIAN ---\n",
    "    t2 = time()\n",
    "    \n",
    "    # Tính toán output\n",
    "    predicted_time = int((t2 - t1) * 1000) # miliseconds\n",
    "    \n",
    "    # Lưu kết quả vào list tổng\n",
    "    all_predicted_time.append({\"id\": video_id, \"answer\": \"processed\", \"time\": predicted_time})\n",
    "    \n",
    "    # Lưu json prediction riêng cho từng video vào object tổng (tuỳ format đề bài, thường là list các object)\n",
    "    all_results_json[video_id] = final_predictions\n",
    "\n",
    "# --- GHI FILE OUTPUT CUỐI CÙNG ---\n",
    "output_dir = \"/result\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 1. File time_submission.csv\n",
    "df_time = pd.DataFrame(all_predicted_time)\n",
    "df_time.to_csv(os.path.join(output_dir, \"time_submission.csv\"), index=False)\n",
    "\n",
    "# 2. File jupyter_submission.json\n",
    "# Format đề bài yêu cầu thường là list các video hoặc dictionary. \n",
    "# Ở đây tôi dump cả cục dictionary chứa tất cả video.\n",
    "with open(os.path.join(output_dir, \"jupyter_submission.json\"), 'w') as f:\n",
    "    json.dump(all_results_json, f, indent=2)\n",
    "\n",
    "print(\"\\n✅ DONE! Output saved to /result/\")\n",
    "print(df_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5e9cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
